# -*- coding: utf-8 -*-
"""Copy of house price prediction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ENzNQLlZoj4VxtkydDwBw9DAKWSifx8U
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plot
import seaborn as sns
import sklearn.datasets
from sklearn.model_selection import train_test_split
from xgboost import XGBRFRegressor
from sklearn import metrics

"""Importing the Boston House price Dataset"""

from sklearn.datasets import fetch_california_housing
house_price_prediction=fetch_california_housing()
print(house_price_prediction)

# Load the California housing dataset
house_price_dataset = fetch_california_housing()

# Convert to a pandas DataFrame including the target
house_price_df = pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)
house_price_df['Target'] = house_price_dataset.target

# Print the DataFrame
print(house_price_df.head())

# Print the number of rows and columns
print(f"Number of rows and columns: {house_price_df.shape}")

#Check for missing values
missing_values = house_price_df.isnull().sum()

# Print the number of missing values for each column
print(missing_values)

# Get statistical measures of the dataset
statistical_measures = house_price_df.describe()

# Print the statistical measures
print(statistical_measures)

"""Understanding the correlation between various in the dataset
1.positive correlation
2.negative correlation
"""

correlation=house_price_prediction.corr()

import pandas as pd
from sklearn.datasets import fetch_california_housing
import seaborn as sns
import matplotlib.pyplot as plt

# Load the California housing dataset
house_price_dataset = fetch_california_housing()

# Convert to a pandas DataFrame including the target
house_price_df = pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)
house_price_df['Target'] = house_price_dataset.target

# Compute the correlation matrix
correlation_matrix = house_price_df.corr()

# Plot the heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)
plt.title('Correlation Matrix of California Housing Dataset')
plt.show()

"""Spliting the data and target"""

# Split the data into features (X) and target variable (y)
X = house_price_df.drop(columns=['Target'])  # Features
y = house_price_df['Target']  # Target variable

# Print the shapes of X and y
print(f"Shape of X: {X.shape}")
print(f"Shape of y: {y.shape}")

"""Spliting the data into Training data and Test data"""

# Split the data into features (X) and target variable (y)
X = house_price_df.drop(columns=['Target'])  # Features
y = house_price_df['Target']  # Target variable

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Print the shapes of the resulting datasets
print(f"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}")
print(f"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}")

"""Model Training
XGBoost Regressor
```
# This is formatted as code
```


"""

import pandas as pd
from sklearn.datasets import fetch_california_housing
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

# Load the California housing dataset
house_price_dataset = fetch_california_housing()

# Convert to a pandas DataFrame including the target
house_price_df = pd.DataFrame(house_price_dataset.data, columns=house_price_dataset.feature_names)
house_price_df['Target'] = house_price_dataset.target

# Split the data into features (X) and target variable (y)
X = house_price_df.drop(columns=['Target'])  # Features
y = house_price_df['Target']  # Target variable

# Split the data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize the linear regression model
model = LinearRegression()

# Train the model on the training data
model.fit(X_train, y_train)

# Predict on the test data
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f"Mean Squared Error (MSE): {mse:.2f}")
print(f"R-squared (R2): {r2:.2f}")

"""Visualizing the actual Prices and predicted prices"""

# Plotting actual vs predicted prices
plt.figure(figsize=(10, 6))

# Scatter plot of actual vs predicted
plt.scatter(y_test, y_pred, color='blue', label='Actual vs Predicted')

# Plotting the perfect fit line
x = np.linspace(min(y_test), max(y_test), 100)
plt.plot(x, x, color='red', linestyle='-', linewidth=2, label='Perfect Fit')

plt.title('Actual Prices vs Predicted Prices')
plt.xlabel('Actual Prices')
plt.ylabel('Predicted Prices')
plt.legend()
plt.grid(True)
plt.show()

"""Prediction on Test Data"""

X_new = X_test.iloc[:5]  # Example: selecting first 5 rows of X_test
y_new_pred = model.predict(X_new)

print("\nPredictions for new data:")
for i, pred in enumerate(y_new_pred):
    print(f"Prediction {i+1}: {pred:.2f}")